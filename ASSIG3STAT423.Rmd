---
title: "STAT 423 Assignment 3"
output:
  word_document: default
  pdf_document: default
  html_notebook: default
---
By Andrew Symes

#**Question 1**

##A 
This would be ratio estimation comparing all news programming to those dedicated solely to sports coverage.

##B 
This would be regression estimation of using the dataset of either previous years catches or conditions.

##C 
This would be regression estimation using previously known and recorded factors for determination.


#**Question 2**

##A
```{r}
Diam <- c(12.0,11.4,7.9,9.0,10.5,7.9,7.3,10.2,11.7,11.3,5.7,8.0,10.3,12.0,9.2,8.5,7.0,10.7,9.3,8.2)
Age <- c(125,119,83,85,99,117,69,133,154,168,61,80,114,147,122,106,82,88,97,99)
Treedf <- data.frame(Diam,Age)
plot(Treedf)
```
##B 
Using Ratio Estimation interval
$$
\widehat{R} \pm (Z_{\frac{\alpha}{2}})*\sqrt{\frac{1}{n*\mu_{X}^{2}}\left(\frac{N - n}{N}\right)S_{R}^{2}} 
$$

```{r}
AveDiam <- mean(Diam)
AveAge <- mean(Age)
sdDiam <- sd(Diam)
sdAge <- sd(Age)
ntree <- sum(ifelse(Diam != 0,1,1))
RhatTree <- AveAge/AveDiam
Treedev <- Age - Diam*RhatTree
SRTree <- sum(Treedev^2)/19

TreeEr <- qnorm(0.975)*sqrt((1/(ntree*10.3^2))*((1132-20)/1132)*SRTree)
Treelb <- 10.3*(RhatTree - TreeEr)
Treeub <- 10.3*(RhatTree + TreeEr)
Treelb
Treeub
TreeEr*10.3
```

$$
109.8267 \leq \mu_Y \leq 125.4141
$$

From the data with 95% confidence we can say that the average age of a tree in the chosen forest to be at least 97.59311 and at most 11.2069. Thanks to the Standard error of 7.793725.

##C
Using
$$
(\widehat{\beta}_{0} + \widehat{\beta}_{1}x_{i}) \pm t_{\frac{\alpha}{2}, df=n-2}*\sqrt{MSE\left(\frac{1}{n} + \frac{(x_{i} - \overline{X})^{2}}{\sum_{i=1}^{n}(X_{i} - \overline{X})^{2}} \right)}
$$
```{r}
Q2reg <- lm(Age~Diam)
treesum <- sum(Age*Diam)
summary(Q2reg)
```

```{r}
predict(Q2reg, newdata=data.frame(Diam=10.3),interval="conf", level=0.95)

```
$$
 108.7079 \leq \mu_Y \leq 128.019
$$
From the data we are 95% confident to conclude that the average Age of a tree with diameter being 10.3 is at least 108.7079 years and at most 128.019 years. 

#**D**
```{r}
plot(Treedf)
abline(b=0,h=108.7079:128.019,v=10.3,col="red")
abline(b=0,h=108.827:125.4141,v=10.3,col="blue")
```
From this graph the ratio estimate appears to work better and maintain a tighter interval.



#**Question 3**

```{r}
library(SDaA)
library(car)
attach(golfsrs)
wk9pro <- ifelse(pro == "y", wkday9, NA)
wk9pro <-na.omit(wk9pro)

avepro <- mean(wk9pro)
varpro <- var(wk9pro)

wk9npro <- ifelse(pro == "n", wkday9, NA)
wk9npro <-na.omit(wk9npro)

avenpro <- mean(wk9npro)
varnpro <- var(wk9npro)

boxplot(wk9npro,wk9pro)
varnpro
varpro
var.test(wk9npro,wk9pro)
print("The variances are certainly different here")

t.test(wk9npro,wk9pro,var.equal = F,level = 0.95)

detach(golfsrs)
```

Using the P-Value 7.669e-08 we can confidently reject the null hypothesis meaning that the average costs of week day 9s are not the same between courses that have professionals available and those that do not.

From the data we can conclude with 95% certainty that the average cost for a week day 9 is atleast 8.48$ to at most 17.35$ more expensive when that golf course has a professional available.


#**Question 4**

##B
Using
$$
\widehat{R} \pm (Z_{\frac{\alpha}{2}})*\sqrt{\frac{1}{n*\mu_{X}^{2}}\left(\frac{N - n}{N}\right)S_{R}^{2}}
$$

```{r}
library(SDaA)
attach(counties)
aveDR <- mean(physicia)
DRt <- qt(0.975,99)
DRVar <- var(physicia)*(3141-1)/3141
SEDR <- DRt*sqrt(DRVar/100*(3141-100)/3141)
DRub <- 3141*(aveDR+SEDR)
DRlb <- 3141*(aveDR-SEDR)
DRub
DRlb
```

$$
 0 \leq T_Y \leq 1909456
$$
From the Data with 95% confidence we can conclude with 95% confidence that the average nuumber of physicians in the United States of America to be at least zero and at most 19099456.
##C

```{r}
plot(physicia,totpop)

```

##D
I believe in this case that using linear regression would work the best due to the appearence of a strong correlation with only one to two potential leverage points
Using
$$
(\widehat{\beta}_{0} + \widehat{\beta}_{1}x_{i}) \pm t_{\frac{\alpha}{2}, df=n-2}*\sqrt{MSE\left(\frac{1}{n} + \frac{(x_{i} - \overline{X})^{2}}{\sum_{i=1}^{n}(X_{i} - \overline{X})^{2}} \right)}
$$

```{r}
Q4reg <- lm(physicia~totpop)
avepop <- mean(totpop)
h <- predict(Q4reg, newdata=data.frame(totpop = 255077536 ),interval="conf", level=0.95)
ub <- h[3]
lb <- h[2]
detach(counties)
ub
lb
```
$$
723174\leq \mu_Y \leq 789140
$$
From the data we can conclude with 95% confidence that the average population size of doctors in the US is between 723174 and 789140.

##E
I believe that the Ratio estimation in this case due to it capturing the true value. This despite Regression having a tighter interval


#**Question 5**

```{r}
Words <-c(62,62,64,56,65,69,59,75,60,71,50,63,55,57,60,64,55,48,62,72,56,51,63,49,52,62,53,58,57,57)
WordsIKnow <-c(33,37,27,22,44,37,43,51,44,48,41,50,41,37,38,38,26,33,30,42,26,31,40,34,29,33,27,29,44,38)
Dictdf <-data.frame(Words,WordsIKnow)
pages <- 963

aveWords <- mean(Words)
aveWordsIKnow <- mean(WordsIKnow)
sWords <- var(Words)*(962)/963
SEWords <- qt(0.975,29)*sqrt(sWords/30*(pages-30)/pages)
Wordtsub<- pages*(aveWords + SEWords)
Wordtslb<- pages*(aveWords - SEWords)
pages*aveWords
Wordtsub
Wordtslb
SEWords
```
```{r}
RhatWords <- aveWordsIKnow/aveWords
Wordsdev <- WordsIKnow - Words*RhatWords
SRWords <- sum(Wordsdev^2)/(30-1)

WordsEr <- qnorm(0.975)*sqrt((1/(30*aveWords^2))*((pages-30)/pages)*SRWords)
Wordspub <- RhatWords + WordsEr
Wordsplb <- RhatWords - WordsEr
Wordspub
Wordsplb
RhatWords
RhatWords*pages*aveWords
pages*Wordspub*aveWords
pages*Wordsplb*aveWords
WordsEr
WordsEr* pages *aveWords
```
$$
0.572981 \leq R \leq 0.6502983 \\ 32867.74 \leq T_{WordsIknow} \leq 37302.86 \\54967.55\leq T_{Words} \leq 59757.85
$$
 From the data the average number of woods in the dictionary would be expected to be 57362.7, but with 95% confidence it is between 54967 and 59758 pages thanks to SE 2.487178. The ammount of words in the dictionary that I may know are between 32867 and 37303 thanks to the SE of 2217.564 and the expectation being 35085. The percent of words I expect to know in the dictionary is 61.16396% with 95% confidence being between 57.2981% and 65.02983% thanks to the SE of 3.865864%. 



#**Question 6**
##A

```{r}
setwd("~/Desktop")
library(ggplot2)
debt <- read.csv("studentdebt.csv",sep = ",")
attach(debt)
ggplot(debt, aes(x=balance,y=income))+geom_point(size=2,shape=2,col="red")
cor(balance,income)
```
There appears to be no linear relationship between the two variables. And with a correlation of two percent the relationship does not appear likely that there is a strong linear relationship.

##B
Using
$$
\widehat{R} \pm (Z_{\frac{\alpha}{2}})*\sqrt{\frac{1}{n*\mu_{X}^{2}}\left(\frac{N - n}{N}\right)S_{R}^{2}}
$$
```{r}
AveINC <- mean(income)
AveBAL <- mean(balance)
sdINC <- sd(income)
sdBAL <- sd(balance)
ndebt <- sum(ifelse(income != 0,1,1))
RhatDebt <- AveBAL/AveINC
Debtdev <- balance - income*RhatDebt
SRDebt <- sum(Debtdev^2)/299

DebtEr <- qnorm(0.975)*sqrt((1/(ndebt*17842^2))*((2098-300)/2098)*SRDebt)
DebtEr
deptlb <- RhatDebt - DebtEr
deptub <- RhatDebt + DebtEr
deptlb
deptub
```
$$
0.05243064\leq R \leq 0.05900483
$$
Given the data, the average debt balance for a university student is between 5.2 percent and 5.9 percent with 95% confidence.

##C
```{r}
deptub2 <- 17842*(deptub)
deptlb2 <- 17842*(deptlb)
totaldeptub <- deptub2 * 2098
totaldeptlb <- deptlb2 * 2098
deptub2
deptlb2
totaldeptub
totaldeptlb
```
$$
 935.4675 \leq \mu_{balance} \leq 1052.764\\
 1962611 \leq T_{balance} \leq 2208699
$$

##D

```{r}
Q6reg <- lm(balance ~ income)
a <- predict(Q6reg, newdata=data.frame(income = 17842 ),interval="conf", level=0.95)
debtubreg <- a[3]
debtlbreg <- a[2]
debtlbreg
debtubreg
totaldeptlbreg <- debtlbreg*2098
totaldeptubreg <- debtubreg*2098
totaldeptlbreg
totaldeptubreg
```
$$
 953.8393 \leq \mu_{balance} \leq 1067.609\\
 2001155 \leq T \leq 2239843
$$

##E

```{r}
par(mfrow= c(2,2))
plot(Q6reg)

```

The two assumptions are normality and constant variance. 
From the plots above the Q-Q plot demonstrates normality, 

With the first plot above Residuals vs Fitted we can observe no difference in the variance of the residuals. This lack of a relationship means that we can go forward with our assumption of constant variance.


##F

```{r}
b <- predict(Q6reg, newdata=data.frame(income = 18500 ),interval="conf", level=0.95)
debtlbreg2 <- b[2]
debtubreg2 <- b[3]
debtlbreg2
debtubreg2
```
$$
955.4058  \leq \mu_{balance} \leq 1069.232
$$
From these data with 95 percent confidence we can say that for students who have 18500$ in annual income they have at least 955.4058$ do debt and atmost 1069.232$ of debt

##G
From the two intervals the regression one seems to have the tightest interval.

##H
using
$$
\widehat{R} \pm (Z_{\frac{\alpha}{2}})*\sqrt{\frac{1}{n*\mu_{X}^{2}}\left(\frac{N - n}{N}\right)S_{R}^{2}}
$$

```{r}
Defaulted <- sum(ifelse(default == "Yes",1,0))
Defaulted
phatdebt <- Defaulted/ndebt
phatdebt
DefER <- qnorm(0.975)*sqrt(phatdebt*(1-phatdebt)/299*(2098-300)/2098)
DefER
phatdebtub <- phatdebt +DefER
phatdebtlb <- phatdebt -DefER
phatdebtub
phatdebtlb
detach(debt)
```
$$
0.01943777 \leq \hat{p}_{defaulted} \leq 0.06056223
$$
From the data we can advise that the proportion of students with credit card outstanding balances who have defaulted is at least 0.01943777, and at most 0.06056223 with 95% confidence.

#**Question 7**
##A
Using
$$
\widehat{R} \pm (Z_{\frac{\alpha}{2}})*\sqrt{\frac{1}{n*\mu_{X}^{2}}\left(\frac{N - n}{N}\right)S_{R}^{2}}
$$

```{r}
ActCrowd <- c(23,14,20,25,12,18,30,27,8,31)
EstCrowd <-c(25,15,22,24,13,18,35,30,10,29)

AveEst <- mean(EstCrowd)
AveAct <- mean(ActCrowd)
RhatCrowd <- AveEst/AveAct
nPictures <- 10

Crowddev <- EstCrowd - ActCrowd*RhatCrowd
SRCrowd <- sum(Crowddev^2)/(nPictures-1)

CrowdEr <- qnorm(0.975)*sqrt((1/(nPictures*22.5^2))*((23232-nPictures)/23232)*SRCrowd)
Crowdlb <- 22.5*23232*(RhatCrowd - CrowdEr)
Crowdub <- 22.5*23232*(RhatCrowd + CrowdEr)
CrowdEr
Crowdub
Crowdlb
```
$$
525796.9\leq T_{YRatio} \leq 584983.1
$$
From the data we can conclude with 95% confidence that the total estimate for the crowd will be between 51972 and 46414.

##B

```{r}
Q7reg <- lm(EstCrowd~ActCrowd)
c <- predict(Q7reg,newdata=data.frame(ActCrowd = 22.5 ),interval="conf", level=0.95)
CrowdubReg <-23232*c[3]
CrowdlbReg <-23232*c[2]
CrowdubReg
CrowdlbReg
```
$$
 516111.2\leq T_{YRegression} \leq589963.6
$$
From the data we can conclude with 95% confidence that the total estimate for the crowd will be between 45707 and 52668.

##C
```{r}
cor(ActCrowd,EstCrowd)
```
The confidence interval for the ratio estimat is much tighter. Despite this I like the regression technique more for this problem due to it using the high correlation seen above. Along with this the regression also capture the true mean*N  meaning that its use will be better for actual estimation.
















